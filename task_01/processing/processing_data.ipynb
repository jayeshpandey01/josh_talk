{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Hindi ASR Dataset Preprocessing\n",
    "Simple step-by-step preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "load_csv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 104\n",
      "Total duration: 21.89 hours\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recording_id</th>\n",
       "      <th>language</th>\n",
       "      <th>duration</th>\n",
       "      <th>rec_url_gcp</th>\n",
       "      <th>transcription_url_gcp</th>\n",
       "      <th>metadata_url_gcp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245746</td>\n",
       "      <td>825780</td>\n",
       "      <td>hi</td>\n",
       "      <td>443</td>\n",
       "      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n",
       "      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n",
       "      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>291038</td>\n",
       "      <td>825727</td>\n",
       "      <td>hi</td>\n",
       "      <td>443</td>\n",
       "      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n",
       "      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n",
       "      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>246004</td>\n",
       "      <td>988596</td>\n",
       "      <td>hi</td>\n",
       "      <td>475</td>\n",
       "      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n",
       "      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n",
       "      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93626</td>\n",
       "      <td>990175</td>\n",
       "      <td>hi</td>\n",
       "      <td>475</td>\n",
       "      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n",
       "      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n",
       "      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>286851</td>\n",
       "      <td>526266</td>\n",
       "      <td>hi</td>\n",
       "      <td>522</td>\n",
       "      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n",
       "      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n",
       "      <td>https://storage.googleapis.com/joshtalks-data-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  recording_id language  duration  \\\n",
       "0   245746        825780       hi       443   \n",
       "1   291038        825727       hi       443   \n",
       "2   246004        988596       hi       475   \n",
       "3    93626        990175       hi       475   \n",
       "4   286851        526266       hi       522   \n",
       "\n",
       "                                         rec_url_gcp  \\\n",
       "0  https://storage.googleapis.com/joshtalks-data-...   \n",
       "1  https://storage.googleapis.com/joshtalks-data-...   \n",
       "2  https://storage.googleapis.com/joshtalks-data-...   \n",
       "3  https://storage.googleapis.com/joshtalks-data-...   \n",
       "4  https://storage.googleapis.com/joshtalks-data-...   \n",
       "\n",
       "                               transcription_url_gcp  \\\n",
       "0  https://storage.googleapis.com/joshtalks-data-...   \n",
       "1  https://storage.googleapis.com/joshtalks-data-...   \n",
       "2  https://storage.googleapis.com/joshtalks-data-...   \n",
       "3  https://storage.googleapis.com/joshtalks-data-...   \n",
       "4  https://storage.googleapis.com/joshtalks-data-...   \n",
       "\n",
       "                                    metadata_url_gcp  \n",
       "0  https://storage.googleapis.com/joshtalks-data-...  \n",
       "1  https://storage.googleapis.com/joshtalks-data-...  \n",
       "2  https://storage.googleapis.com/joshtalks-data-...  \n",
       "3  https://storage.googleapis.com/joshtalks-data-...  \n",
       "4  https://storage.googleapis.com/joshtalks-data-...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../dataset/FT Data - data.csv')\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Total duration: {df['duration'].sum() / 3600:.2f} hours\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fix_urls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs fixed\n",
      "Sample URL: https://storage.googleapis.com/upload_goai/hq_data/hi/967179/825780_transcription.json\n"
     ]
    }
   ],
   "source": [
    "# Fix URLs\n",
    "df['rec_url_gcp'] = df['rec_url_gcp'].str.replace('joshtalks-data-collection', 'upload_goai')\n",
    "df['transcription_url_gcp'] = df['transcription_url_gcp'].str.replace('joshtalks-data-collection', 'upload_goai')\n",
    "print(\"URLs fixed\")\n",
    "print(\"Sample URL:\", df['transcription_url_gcp'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "create_dirs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories created\n"
     ]
    }
   ],
   "source": [
    "# Create directories\n",
    "os.makedirs('audio', exist_ok=True)\n",
    "os.makedirs('transcriptions', exist_ok=True)\n",
    "print(\"Directories created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "download_process",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [01:24<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download and process\n",
    "processed_data = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    recording_id = row['recording_id']\n",
    "    audio_path = f\"audio/{recording_id}.wav\"\n",
    "    trans_path = f\"transcriptions/{recording_id}.json\"\n",
    "    \n",
    "    # Download audio\n",
    "    if not os.path.exists(audio_path):\n",
    "        try:\n",
    "            r = requests.get(row['rec_url_gcp'], timeout=30)\n",
    "            with open(audio_path, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Download transcription\n",
    "    if not os.path.exists(trans_path):\n",
    "        try:\n",
    "            r = requests.get(row['transcription_url_gcp'], timeout=30)\n",
    "            with open(trans_path, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Process transcription\n",
    "    try:\n",
    "        with open(trans_path, 'r', encoding='utf-8') as f:\n",
    "            trans_data = json.load(f)\n",
    "        text = ' '.join([seg['text'] for seg in trans_data if 'text' in seg])\n",
    "        \n",
    "        processed_data.append({\n",
    "            'audio': audio_path,\n",
    "            'text': text.strip(),\n",
    "            'recording_id': recording_id,\n",
    "            'user_id': row['user_id'],\n",
    "            'duration': row['duration']\n",
    "        })\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"Processed {len(processed_data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a509200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: colorama in C:\\Users\\jayes\\AppData\\Roaming\\Python\\Python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages (from requests->transformers) (2025.11.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d24111c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datasets import Dataset, Audio, DatasetDict, load_dataset\n",
    "from transformers import (\n",
    "    WhisperProcessor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "import torch\n",
    "import evaluate\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0529b150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in CSV: 104\n",
      "Error processing 825780: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 825727: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 988596: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 990175: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 526266: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 520199: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 542785: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 494019: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 523045: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 522951: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 254219: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 253253: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 351501: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 350606: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 629904: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 635909: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 989901: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 990783: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 240907: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 240909: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 270153: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 270150: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 475392: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 475356: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 255349: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 255381: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 767685: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 767869: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 886193: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 888331: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 615351: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 615319: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 738845: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 739630: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 272241: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 282447: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 270296: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 270291: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 365033: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 365059: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 661889: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 661767: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 239492: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 241695: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 350297: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 350347: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 269794: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 269383: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 240994: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 243702: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 537776: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 537983: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 630221: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 630926: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 583544: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 583552: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 584003: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 583991: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 978393: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 978484: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 629868: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 629862: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 443952: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 444282: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 302506: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 302503: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 645534: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 644742: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 330457: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 319431: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 979497: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 977253: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 238123: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 238079: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 305347: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 305308: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 489675: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 489638: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 781184: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 781268: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 663529: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 661461: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 583533: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 583334: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 798121: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 783966: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 400490: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 400503: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 857737: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 856801: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 301080: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 301057: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 367249: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 366972: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 269907: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 270037: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 319105: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 319126: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 754618: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 753435: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 1021370: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 1020918: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 840793: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing 840781: Expecting value: line 1 column 1 (char 0)\n",
      "Valid samples: 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/FT Data - data.csv')\n",
    "print(f\"Total samples in CSV: {len(df)}\")\n",
    "\n",
    "# Process transcriptions and create dataset\n",
    "data_list = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    recording_id = row['recording_id']\n",
    "    audio_path = f\"audio/{recording_id}.wav\"\n",
    "    trans_path = f\"transcriptions/{recording_id}.json\"\n",
    "    \n",
    "    if not os.path.exists(audio_path) or not os.path.exists(trans_path):\n",
    "        continue\n",
    "    try:\n",
    "        with open(trans_path, 'r', encoding='utf-8') as f:\n",
    "            trans_data = json.load(f)\n",
    "        \n",
    "        # Combine all text segments\n",
    "        text = ' '.join([seg['text'] for seg in trans_data if 'text' in seg])\n",
    "        \n",
    "        if text.strip():\n",
    "            data_list.append({\n",
    "                'audio': audio_path,\n",
    "                'text': text.strip(),\n",
    "                'user_id': row['user_id']\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {recording_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Valid samples: {len(data_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62a3daf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['audio/1020918.wav',\n",
       "  'audio/1021370.wav',\n",
       "  'audio/238079.wav',\n",
       "  'audio/238123.wav',\n",
       "  'audio/239492.wav',\n",
       "  'audio/240907.wav',\n",
       "  'audio/240909.wav',\n",
       "  'audio/240994.wav',\n",
       "  'audio/241695.wav',\n",
       "  'audio/243702.wav',\n",
       "  'audio/253253.wav',\n",
       "  'audio/254219.wav',\n",
       "  'audio/255349.wav',\n",
       "  'audio/255381.wav',\n",
       "  'audio/269383.wav',\n",
       "  'audio/269794.wav',\n",
       "  'audio/269907.wav',\n",
       "  'audio/270037.wav',\n",
       "  'audio/270150.wav',\n",
       "  'audio/270153.wav',\n",
       "  'audio/270291.wav',\n",
       "  'audio/270296.wav',\n",
       "  'audio/272241.wav',\n",
       "  'audio/282447.wav',\n",
       "  'audio/301057.wav',\n",
       "  'audio/301080.wav',\n",
       "  'audio/302503.wav',\n",
       "  'audio/302506.wav',\n",
       "  'audio/305308.wav',\n",
       "  'audio/305347.wav',\n",
       "  'audio/319105.wav',\n",
       "  'audio/319126.wav',\n",
       "  'audio/319431.wav',\n",
       "  'audio/330457.wav',\n",
       "  'audio/350297.wav',\n",
       "  'audio/350347.wav',\n",
       "  'audio/350606.wav',\n",
       "  'audio/351501.wav',\n",
       "  'audio/365033.wav',\n",
       "  'audio/365059.wav',\n",
       "  'audio/366972.wav',\n",
       "  'audio/367249.wav',\n",
       "  'audio/400490.wav',\n",
       "  'audio/400503.wav',\n",
       "  'audio/443952.wav',\n",
       "  'audio/444282.wav',\n",
       "  'audio/475356.wav',\n",
       "  'audio/475392.wav',\n",
       "  'audio/489638.wav',\n",
       "  'audio/489675.wav',\n",
       "  'audio/494019.wav',\n",
       "  'audio/520199.wav',\n",
       "  'audio/522951.wav',\n",
       "  'audio/523045.wav',\n",
       "  'audio/526266.wav',\n",
       "  'audio/537776.wav',\n",
       "  'audio/537983.wav',\n",
       "  'audio/542785.wav',\n",
       "  'audio/583334.wav',\n",
       "  'audio/583533.wav',\n",
       "  'audio/583544.wav',\n",
       "  'audio/583552.wav',\n",
       "  'audio/583991.wav',\n",
       "  'audio/584003.wav',\n",
       "  'audio/615319.wav',\n",
       "  'audio/615351.wav',\n",
       "  'audio/629862.wav',\n",
       "  'audio/629868.wav',\n",
       "  'audio/629904.wav',\n",
       "  'audio/630221.wav',\n",
       "  'audio/630926.wav',\n",
       "  'audio/635909.wav',\n",
       "  'audio/644742.wav',\n",
       "  'audio/645534.wav',\n",
       "  'audio/661461.wav',\n",
       "  'audio/661767.wav',\n",
       "  'audio/661889.wav',\n",
       "  'audio/663529.wav',\n",
       "  'audio/738845.wav',\n",
       "  'audio/739630.wav',\n",
       "  'audio/753435.wav',\n",
       "  'audio/754618.wav',\n",
       "  'audio/767685.wav',\n",
       "  'audio/767869.wav',\n",
       "  'audio/781184.wav',\n",
       "  'audio/781268.wav',\n",
       "  'audio/783966.wav',\n",
       "  'audio/798121.wav',\n",
       "  'audio/825727.wav',\n",
       "  'audio/825780.wav',\n",
       "  'audio/840781.wav',\n",
       "  'audio/840793.wav',\n",
       "  'audio/856801.wav',\n",
       "  'audio/857737.wav',\n",
       "  'audio/886193.wav',\n",
       "  'audio/888331.wav',\n",
       "  'audio/977253.wav',\n",
       "  'audio/978393.wav',\n",
       "  'audio/978484.wav',\n",
       "  'audio/979497.wav',\n",
       "  'audio/988596.wav',\n",
       "  'audio/989901.wav',\n",
       "  'audio/990175.wav',\n",
       "  'audio/990783.wav'],\n",
       " ['transcriptions/1020918.json',\n",
       "  'transcriptions/1021370.json',\n",
       "  'transcriptions/238079.json',\n",
       "  'transcriptions/238123.json',\n",
       "  'transcriptions/239492.json',\n",
       "  'transcriptions/240907.json',\n",
       "  'transcriptions/240909.json',\n",
       "  'transcriptions/240994.json',\n",
       "  'transcriptions/241695.json',\n",
       "  'transcriptions/243702.json',\n",
       "  'transcriptions/253253.json',\n",
       "  'transcriptions/254219.json',\n",
       "  'transcriptions/255349.json',\n",
       "  'transcriptions/255381.json',\n",
       "  'transcriptions/269383.json',\n",
       "  'transcriptions/269794.json',\n",
       "  'transcriptions/269907.json',\n",
       "  'transcriptions/270037.json',\n",
       "  'transcriptions/270150.json',\n",
       "  'transcriptions/270153.json',\n",
       "  'transcriptions/270291.json',\n",
       "  'transcriptions/270296.json',\n",
       "  'transcriptions/272241.json',\n",
       "  'transcriptions/282447.json',\n",
       "  'transcriptions/301057.json',\n",
       "  'transcriptions/301080.json',\n",
       "  'transcriptions/302503.json',\n",
       "  'transcriptions/302506.json',\n",
       "  'transcriptions/305308.json',\n",
       "  'transcriptions/305347.json',\n",
       "  'transcriptions/319105.json',\n",
       "  'transcriptions/319126.json',\n",
       "  'transcriptions/319431.json',\n",
       "  'transcriptions/330457.json',\n",
       "  'transcriptions/350297.json',\n",
       "  'transcriptions/350347.json',\n",
       "  'transcriptions/350606.json',\n",
       "  'transcriptions/351501.json',\n",
       "  'transcriptions/365033.json',\n",
       "  'transcriptions/365059.json',\n",
       "  'transcriptions/366972.json',\n",
       "  'transcriptions/367249.json',\n",
       "  'transcriptions/400490.json',\n",
       "  'transcriptions/400503.json',\n",
       "  'transcriptions/443952.json',\n",
       "  'transcriptions/444282.json',\n",
       "  'transcriptions/475356.json',\n",
       "  'transcriptions/475392.json',\n",
       "  'transcriptions/489638.json',\n",
       "  'transcriptions/489675.json',\n",
       "  'transcriptions/494019.json',\n",
       "  'transcriptions/520199.json',\n",
       "  'transcriptions/522951.json',\n",
       "  'transcriptions/523045.json',\n",
       "  'transcriptions/526266.json',\n",
       "  'transcriptions/537776.json',\n",
       "  'transcriptions/537983.json',\n",
       "  'transcriptions/542785.json',\n",
       "  'transcriptions/583334.json',\n",
       "  'transcriptions/583533.json',\n",
       "  'transcriptions/583544.json',\n",
       "  'transcriptions/583552.json',\n",
       "  'transcriptions/583991.json',\n",
       "  'transcriptions/584003.json',\n",
       "  'transcriptions/615319.json',\n",
       "  'transcriptions/615351.json',\n",
       "  'transcriptions/629862.json',\n",
       "  'transcriptions/629868.json',\n",
       "  'transcriptions/629904.json',\n",
       "  'transcriptions/630221.json',\n",
       "  'transcriptions/630926.json',\n",
       "  'transcriptions/635909.json',\n",
       "  'transcriptions/644742.json',\n",
       "  'transcriptions/645534.json',\n",
       "  'transcriptions/661461.json',\n",
       "  'transcriptions/661767.json',\n",
       "  'transcriptions/661889.json',\n",
       "  'transcriptions/663529.json',\n",
       "  'transcriptions/738845.json',\n",
       "  'transcriptions/739630.json',\n",
       "  'transcriptions/753435.json',\n",
       "  'transcriptions/754618.json',\n",
       "  'transcriptions/767685.json',\n",
       "  'transcriptions/767869.json',\n",
       "  'transcriptions/781184.json',\n",
       "  'transcriptions/781268.json',\n",
       "  'transcriptions/783966.json',\n",
       "  'transcriptions/798121.json',\n",
       "  'transcriptions/825727.json',\n",
       "  'transcriptions/825780.json',\n",
       "  'transcriptions/840781.json',\n",
       "  'transcriptions/840793.json',\n",
       "  'transcriptions/856801.json',\n",
       "  'transcriptions/857737.json',\n",
       "  'transcriptions/886193.json',\n",
       "  'transcriptions/888331.json',\n",
       "  'transcriptions/977253.json',\n",
       "  'transcriptions/978393.json',\n",
       "  'transcriptions/978484.json',\n",
       "  'transcriptions/979497.json',\n",
       "  'transcriptions/988596.json',\n",
       "  'transcriptions/989901.json',\n",
       "  'transcriptions/990175.json',\n",
       "  'transcriptions/990783.json'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio = []\n",
    "transcription = []\n",
    "import os\n",
    "for fname in sorted(os.listdir('audio')):\n",
    "    if not fname.lower().endswith(('.wav', '.mp3', '.flac')):\n",
    "        continue\n",
    "    rid = os.path.splitext(fname)[0]\n",
    "    a_path = f'audio/{fname}'\n",
    "    t_path = f'transcriptions/{rid}.json'\n",
    "    if os.path.exists(t_path):\n",
    "        audio.append(a_path)\n",
    "        transcription.append(t_path)\n",
    "\n",
    "audio, transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c76583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('audio/1020918.wav', 'transcriptions/1020918.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio[0], transcription[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc865720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio/1020918.wav</td>\n",
       "      <td>transcriptions/1020918.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio/1021370.wav</td>\n",
       "      <td>transcriptions/1021370.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio/238079.wav</td>\n",
       "      <td>transcriptions/238079.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio/238123.wav</td>\n",
       "      <td>transcriptions/238123.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio/239492.wav</td>\n",
       "      <td>transcriptions/239492.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               audio                transcription\n",
       "0  audio/1020918.wav  transcriptions/1020918.json\n",
       "1  audio/1021370.wav  transcriptions/1021370.json\n",
       "2   audio/238079.wav   transcriptions/238079.json\n",
       "3   audio/238123.wav   transcriptions/238123.json\n",
       "4   audio/239492.wav   transcriptions/239492.json"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conert into the df formate\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'audio': audio, 'transcription': transcription})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbcd920a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m train_df, val_df = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muser_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2940\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2936\u001b[39m         CVClass = ShuffleSplit\n\u001b[32m   2938\u001b[39m     cv = CVClass(test_size=n_test, train_size=n_train, random_state=random_state)\n\u001b[32m-> \u001b[39m\u001b[32m2940\u001b[39m     train, test = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2942\u001b[39m train, test = ensure_common_namespace_device(arrays[\u001b[32m0\u001b[39m], train, test)\n\u001b[32m   2944\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   2945\u001b[39m     chain.from_iterable(\n\u001b[32m   2946\u001b[39m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[32m   2947\u001b[39m     )\n\u001b[32m   2948\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:1927\u001b[39m, in \u001b[36mBaseShuffleSplit.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m   1897\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[32m   1898\u001b[39m \n\u001b[32m   1899\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1924\u001b[39m \u001b[33;03mto an integer.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1926\u001b[39m X, y, groups = indexable(X, y, groups)\n\u001b[32m-> \u001b[39m\u001b[32m1927\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1928\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jayes\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2342\u001b[39m, in \u001b[36mStratifiedShuffleSplit._iter_indices\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m   2340\u001b[39m class_counts = np.bincount(y_indices)\n\u001b[32m   2341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.min(class_counts) < \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2342\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2343\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe least populated class in y has only 1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2344\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m member, which is too few. The minimum\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2345\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m number of groups for any class cannot\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2346\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m be less than 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2347\u001b[39m     )\n\u001b[32m   2349\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train < n_classes:\n\u001b[32m   2350\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2351\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m should be greater or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2352\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m % (n_train, n_classes)\n\u001b[32m   2353\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=df['user_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f34b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
