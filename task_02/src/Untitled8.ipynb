{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpFprgT4BTig",
        "outputId": "6507eb0b-f8c0-4822-f05a-6d938349d5f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting whisper_timestamped\n",
            "  Downloading whisper_timestamped-1.15.9-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from whisper_timestamped) (3.0.12)\n",
            "Collecting dtw-python (from whisper_timestamped)\n",
            "  Downloading dtw_python-1.7.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting openai-whisper (from whisper_timestamped)\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=2.0 in /usr/local/lib/python3.12/dist-packages (from dtw-python->whisper_timestamped) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from dtw-python->whisper_timestamped) (1.16.3)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper_timestamped) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper_timestamped) (0.60.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper_timestamped) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper_timestamped) (2.10.0+cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper_timestamped) (4.67.3)\n",
            "Collecting triton>=2 (from openai-whisper->whisper_timestamped)\n",
            "  Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper->whisper_timestamped) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper->whisper_timestamped) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper->whisper_timestamped) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper_timestamped) (3.24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper_timestamped) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper_timestamped) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper_timestamped) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper_timestamped) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper_timestamped) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper_timestamped) (2025.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper_timestamped) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper_timestamped) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper_timestamped) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper_timestamped) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper->whisper_timestamped) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper->whisper_timestamped) (3.0.3)\n",
            "Downloading whisper_timestamped-1.15.9-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dtw_python-1.7.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (825 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.0/825.0 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803980 sha256=90851d3bebe7e195a5ea531e4f70c24b6163b9e9b7e0603f7cac1f8b5e3e0280\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, dtw-python, openai-whisper, whisper_timestamped\n",
            "Successfully installed dtw-python-1.7.4 openai-whisper-20250625 triton-3.6.0 whisper_timestamped-1.15.9\n"
          ]
        }
      ],
      "source": [
        "!pip install whisper_timestamped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple, Optional, Set\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Audio processing\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import detect_silence\n",
        "\n",
        "# ASR with timestamps\n",
        "import whisper_timestamped as whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HindiDisfluencyDetectorV2:\n",
        "    def __init__(self, disfluency_list_path: str = \"/content/Speech Disfluencies List - Sheet1.csv\"):\n",
        "        self.load_disfluency_patterns(disfluency_list_path)\n",
        "        self.whisper_model = None\n",
        "\n",
        "        self.min_filler_duration = 0.15\n",
        "        self.min_prolongation_duration = 0.25\n",
        "        self.min_repetition_duration = 0.30\n",
        "        self.min_hesitation_duration = 0.40\n",
        "        self.min_false_start_duration = 0.15\n",
        "\n",
        "        self.min_confidence = 0.60\n",
        "\n",
        "        self.max_repetition_gap = 0.5\n",
        "\n",
        "        self.common_words = {\n",
        "            'जी', 'हाँ', 'नहीं', 'है', 'था', 'थे', 'हम', 'को', 'जो',\n",
        "            'के', 'ने', 'तो', 'पर', 'से', 'में', 'और', 'या', 'भी',\n",
        "            'अच्छा', 'ठीक', 'सही', 'अरे', 'अच्छी', 'पूरी', 'पराठा'\n",
        "        }\n",
        "\n",
        "        self.known_fillers = {\n",
        "            'उम्म', 'हम्म', 'अम्म', 'एम्म', 'मतलब', 'जैसे', 'वैसे',\n",
        "            'यानी', 'क्या', 'अरे', 'हाँ', 'तो', 'वो', 'ये', 'उह',\n",
        "            'आह', 'ओह', 'एह', 'इह'\n",
        "        }\n",
        "\n",
        "    def load_disfluency_patterns(self, csv_path: str):\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        self.fillers = self._extract_patterns(df['Filled Pause'])\n",
        "        self.repetitions = self._extract_patterns(df['Repetition'])\n",
        "        self.false_starts = self._extract_patterns(df['False Start'])\n",
        "        self.prolongations = self._extract_patterns(df['Prolongation'])\n",
        "        self.self_corrections = self._extract_patterns(df['Self-Correction'])\n",
        "\n",
        "        print(f\"✓ Loaded {len(self.fillers)} filler patterns\")\n",
        "\n",
        "    def _extract_patterns(self, series: pd.Series) -> List[str]:\n",
        "        return [str(x).strip() for x in series.dropna() if str(x).strip()]\n",
        "\n",
        "    def load_whisper_model(self, model_size: str = \"medium\"):\n",
        "        print(f\"Loading Whisper {model_size} model...\")\n",
        "        self.whisper_model = whisper.load_model(model_size)\n",
        "        print(\"✓ Whisper model loaded\")\n",
        "\n",
        "    def transcribe_with_timestamps(self, audio_path: str) -> Dict:\n",
        "        if self.whisper_model is None:\n",
        "            self.load_whisper_model()\n",
        "\n",
        "        audio_path = os.path.abspath(audio_path)\n",
        "        if not os.path.exists(audio_path):\n",
        "            raise FileNotFoundError(f\"Audio file not found: {audio_path}\")\n",
        "\n",
        "        initial_prompt = (\n",
        "            \"उम्म... मतलब... जैसे... तो... हम्म... मैं... मैं... \"\n",
        "            \"क्या... क्या बोल रहे थे... अरे... हाँ... सोoooo... \"\n",
        "            \"अच्छ्छ्छा... वो... वो... ये... ये...\"\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            result = whisper.transcribe(\n",
        "                self.whisper_model,\n",
        "                audio_path,\n",
        "                language=\"hi\",\n",
        "                detect_disfluencies=True,\n",
        "                initial_prompt=initial_prompt,\n",
        "                vad=False\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error during transcription: {e}\")\n",
        "            raise\n",
        "\n",
        "        return result\n",
        "\n",
        "    def normalize_word(self, word: str) -> str:\n",
        "        normalized = re.sub(r'[।,\\.…\\-—!?;:]', '', word)\n",
        "        normalized = normalized.strip().lower()\n",
        "        return normalized\n",
        "\n",
        "    def is_common_word(self, word: str) -> bool:\n",
        "        normalized = self.normalize_word(word)\n",
        "        return normalized in self.common_words\n",
        "\n",
        "    def is_known_filler(self, word: str) -> bool:\n",
        "        normalized = self.normalize_word(word)\n",
        "        return normalized in self.known_fillers\n",
        "\n",
        "    def detect_fillers(self, word_timestamps: List[Dict]) -> List[Dict]:\n",
        "        detections = []\n",
        "\n",
        "        for word_info in word_timestamps:\n",
        "            word = word_info.get('text', '').strip()\n",
        "            start = word_info.get('start', 0)\n",
        "            end = word_info.get('end', 0)\n",
        "            duration = end - start\n",
        "            confidence = word_info.get('confidence', 0.0)\n",
        "\n",
        "            if duration < self.min_filler_duration:\n",
        "                continue\n",
        "            if confidence < self.min_confidence:\n",
        "                continue\n",
        "\n",
        "            if self.is_known_filler(word):\n",
        "                detections.append({\n",
        "                    'type': 'filler',\n",
        "                    'subtype': self.normalize_word(word),\n",
        "                    'text': word,\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'confidence': confidence\n",
        "                })\n",
        "                continue\n",
        "\n",
        "            normalized_word = self.normalize_word(word)\n",
        "            for filler in self.fillers:\n",
        "                normalized_filler = self.normalize_word(filler)\n",
        "                if normalized_word == normalized_filler:\n",
        "                    detections.append({\n",
        "                        'type': 'filler',\n",
        "                        'subtype': filler,\n",
        "                        'text': word,\n",
        "                        'start': start,\n",
        "                        'end': end,\n",
        "                        'confidence': confidence\n",
        "                    })\n",
        "                    break\n",
        "\n",
        "        return detections\n",
        "\n",
        "    def detect_repetitions(self, word_timestamps: List[Dict]) -> List[Dict]:\n",
        "        detections = []\n",
        "        seen = set()\n",
        "\n",
        "        for i in range(len(word_timestamps) - 1):\n",
        "            current = word_timestamps[i].get('text', '').strip()\n",
        "            next_word = word_timestamps[i + 1].get('text', '').strip()\n",
        "\n",
        "            current_norm = self.normalize_word(current)\n",
        "            next_norm = self.normalize_word(next_word)\n",
        "\n",
        "            if not current_norm or not next_norm or len(current_norm) < 2:\n",
        "                continue\n",
        "\n",
        "            if self.is_common_word(current):\n",
        "                continue\n",
        "\n",
        "            if current_norm == next_norm:\n",
        "                start = word_timestamps[i].get('start', 0)\n",
        "                end = word_timestamps[i + 1].get('end', 0)\n",
        "                duration = end - start\n",
        "\n",
        "                if duration < self.min_repetition_duration:\n",
        "                    continue\n",
        "\n",
        "                conf1 = word_timestamps[i].get('confidence', 0.0)\n",
        "                conf2 = word_timestamps[i + 1].get('confidence', 0.0)\n",
        "                avg_conf = (conf1 + conf2) / 2\n",
        "\n",
        "                if avg_conf < self.min_confidence:\n",
        "                    continue\n",
        "\n",
        "                gap = word_timestamps[i + 1].get('start', 0) - word_timestamps[i].get('end', 0)\n",
        "                if gap > self.max_repetition_gap:\n",
        "                    continue\n",
        "\n",
        "                key = (round(start, 2), round(end, 2))\n",
        "                if key in seen:\n",
        "                    continue\n",
        "                seen.add(key)\n",
        "\n",
        "                detections.append({\n",
        "                    'type': 'repetition',\n",
        "                    'subtype': 'immediate',\n",
        "                    'text': f\"{current} {next_word}\",\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'confidence': avg_conf\n",
        "                })\n",
        "\n",
        "        return detections\n",
        "\n",
        "    def detect_prolongations(self, word_timestamps: List[Dict]) -> List[Dict]:\n",
        "        detections = []\n",
        "        seen = set()\n",
        "\n",
        "        for word_info in word_timestamps:\n",
        "            word = word_info.get('text', '').strip()\n",
        "            start = word_info.get('start', 0)\n",
        "            end = word_info.get('end', 0)\n",
        "            duration = end - start\n",
        "            confidence = word_info.get('confidence', 0.0)\n",
        "\n",
        "            if duration < self.min_prolongation_duration:\n",
        "                continue\n",
        "            if confidence < self.min_confidence:\n",
        "                continue\n",
        "\n",
        "            if self.is_common_word(word):\n",
        "                continue\n",
        "\n",
        "            has_elongation = False\n",
        "\n",
        "            if '...' in word or '…' in word:\n",
        "                has_elongation = True\n",
        "            elif re.search(r'([a-zA-Z])\\1{4,}', word):\n",
        "                has_elongation = True\n",
        "            elif re.search(r'([ाीुूेैोौं])\\1{4,}', word):\n",
        "                has_elongation = True\n",
        "\n",
        "            if has_elongation:\n",
        "                key = (round(start, 2), round(end, 2))\n",
        "                if key in seen:\n",
        "                    continue\n",
        "                seen.add(key)\n",
        "\n",
        "                detections.append({\n",
        "                    'type': 'prolongation',\n",
        "                    'subtype': 'elongation',\n",
        "                    'text': word,\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'confidence': confidence\n",
        "                })\n",
        "\n",
        "        return detections\n",
        "\n",
        "    def detect_false_starts(self, word_timestamps: List[Dict]) -> List[Dict]:\n",
        "        detections = []\n",
        "        seen = set()\n",
        "\n",
        "        for word_info in word_timestamps:\n",
        "            word = word_info.get('text', '').strip()\n",
        "            start = word_info.get('start', 0)\n",
        "            end = word_info.get('end', 0)\n",
        "            duration = end - start\n",
        "            confidence = word_info.get('confidence', 0.0)\n",
        "\n",
        "            if duration < self.min_false_start_duration:\n",
        "                continue\n",
        "            if confidence < self.min_confidence:\n",
        "                continue\n",
        "\n",
        "            if self.is_common_word(word):\n",
        "                continue\n",
        "\n",
        "            has_truncation = word.endswith('—') or word.endswith('-')\n",
        "\n",
        "            word_clean = self.normalize_word(word)\n",
        "            is_suspicious = (\n",
        "                len(word_clean) <= 2 and\n",
        "                not word_clean.isdigit() and\n",
        "                duration < 0.25\n",
        "            )\n",
        "\n",
        "            if has_truncation or is_suspicious:\n",
        "                key = (round(start, 2), round(end, 2))\n",
        "                if key in seen:\n",
        "                    continue\n",
        "                seen.add(key)\n",
        "\n",
        "                detections.append({\n",
        "                    'type': 'false_start',\n",
        "                    'subtype': 'truncated',\n",
        "                    'text': word,\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'confidence': confidence\n",
        "                })\n",
        "\n",
        "        return detections\n",
        "\n",
        "    def detect_hesitations(self, audio_path: str, word_timestamps: List[Dict]) -> List[Dict]:\n",
        "        detections = []\n",
        "        seen = set()\n",
        "\n",
        "        try:\n",
        "            audio = AudioSegment.from_file(audio_path)\n",
        "\n",
        "            silences = detect_silence(\n",
        "                audio,\n",
        "                min_silence_len=int(self.min_hesitation_duration * 1000),\n",
        "                silence_thresh=audio.dBFS - 16\n",
        "            )\n",
        "\n",
        "            for i in range(len(word_timestamps) - 1):\n",
        "                end_current = word_timestamps[i].get('end', 0) * 1000\n",
        "                start_next = word_timestamps[i + 1].get('start', 0) * 1000\n",
        "\n",
        "                gap_duration = start_next - end_current\n",
        "\n",
        "                if gap_duration >= self.min_hesitation_duration * 1000:\n",
        "                    start_sec = end_current / 1000\n",
        "                    end_sec = start_next / 1000\n",
        "\n",
        "                    key = (round(start_sec, 2), round(end_sec, 2))\n",
        "                    if key in seen:\n",
        "                        continue\n",
        "                    seen.add(key)\n",
        "\n",
        "                    detections.append({\n",
        "                        'type': 'hesitation',\n",
        "                        'subtype': 'pause',\n",
        "                        'text': '[PAUSE]',\n",
        "                        'start': start_sec,\n",
        "                        'end': end_sec,\n",
        "                        'confidence': 1.0,\n",
        "                        'duration_ms': gap_duration\n",
        "                    })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not detect hesitations: {e}\")\n",
        "\n",
        "        return detections\n",
        "\n",
        "    def remove_overlaps(self, detections: List[Dict]) -> List[Dict]:\n",
        "        if not detections:\n",
        "            return []\n",
        "\n",
        "        sorted_detections = sorted(\n",
        "            detections,\n",
        "            key=lambda x: (x['start'], -x.get('confidence', 0))\n",
        "        )\n",
        "\n",
        "        filtered = []\n",
        "\n",
        "        for detection in sorted_detections:\n",
        "            overlaps = False\n",
        "\n",
        "            for existing in filtered:\n",
        "                overlap_start = max(detection['start'], existing['start'])\n",
        "                overlap_end = min(detection['end'], existing['end'])\n",
        "\n",
        "                if overlap_start < overlap_end:\n",
        "                    overlap_duration = overlap_end - overlap_start\n",
        "                    det_duration = detection['end'] - detection['start']\n",
        "                    exist_duration = existing['end'] - existing['start']\n",
        "\n",
        "                    overlap_pct_det = overlap_duration / det_duration if det_duration > 0 else 0\n",
        "                    overlap_pct_exist = overlap_duration / exist_duration if exist_duration > 0 else 0\n",
        "\n",
        "                    if overlap_pct_det > 0.5 or overlap_pct_exist > 0.5:\n",
        "                        if detection.get('confidence', 0) > existing.get('confidence', 0):\n",
        "                            filtered.remove(existing)\n",
        "                            filtered.append(detection)\n",
        "                        overlaps = True\n",
        "                        break\n",
        "\n",
        "            if not overlaps:\n",
        "                filtered.append(detection)\n",
        "\n",
        "        return filtered\n",
        "\n",
        "    def detect_all_disfluencies(self, audio_path: str) -> Tuple[List[Dict], Dict]:\n",
        "        print(f\"\\nProcessing: {audio_path}\")\n",
        "\n",
        "        print(\"  → Transcribing with Whisper...\")\n",
        "        result = self.transcribe_with_timestamps(audio_path)\n",
        "\n",
        "        word_timestamps = []\n",
        "        for segment in result.get('segments', []):\n",
        "            for word in segment.get('words', []):\n",
        "                word_timestamps.append(word)\n",
        "\n",
        "        print(f\"  → Found {len(word_timestamps)} words\")\n",
        "\n",
        "        all_detections = []\n",
        "\n",
        "        print(\"  → Detecting fillers...\")\n",
        "        fillers = self.detect_fillers(word_timestamps)\n",
        "        all_detections.extend(fillers)\n",
        "        print(f\"     Found {len(fillers)} fillers\")\n",
        "\n",
        "        print(\"  → Detecting repetitions...\")\n",
        "        repetitions = self.detect_repetitions(word_timestamps)\n",
        "        all_detections.extend(repetitions)\n",
        "        print(f\"     Found {len(repetitions)} repetitions\")\n",
        "\n",
        "        print(\"  → Detecting prolongations...\")\n",
        "        prolongations = self.detect_prolongations(word_timestamps)\n",
        "        all_detections.extend(prolongations)\n",
        "        print(f\"     Found {len(prolongations)} prolongations\")\n",
        "\n",
        "        print(\"  → Detecting false starts...\")\n",
        "        false_starts = self.detect_false_starts(word_timestamps)\n",
        "        all_detections.extend(false_starts)\n",
        "        print(f\"     Found {len(false_starts)} false starts\")\n",
        "\n",
        "        print(\"  → Detecting hesitations...\")\n",
        "        hesitations = self.detect_hesitations(audio_path, word_timestamps)\n",
        "        all_detections.extend(hesitations)\n",
        "        print(f\"     Found {len(hesitations)} hesitations\")\n",
        "\n",
        "        print(\"  → Removing overlaps...\")\n",
        "        all_detections = self.remove_overlaps(all_detections)\n",
        "\n",
        "        all_detections.sort(key=lambda x: x['start'])\n",
        "\n",
        "        print(f\"  ✓ Total unique disfluencies: {len(all_detections)}\")\n",
        "\n",
        "        return all_detections, result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AudioClipper:\n",
        "    def __init__(self, output_dir: str = \"output/disfluency_clips\"):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def extract_clip(self, audio_path: str, start_sec: float, end_sec: float,\n",
        "                     output_filename: str, padding_ms: int = 200) -> str:\n",
        "        try:\n",
        "            audio = AudioSegment.from_file(audio_path)\n",
        "            start_ms = max(0, int(start_sec * 1000) - padding_ms)\n",
        "            end_ms = min(len(audio), int(end_sec * 1000) + padding_ms)\n",
        "            clip = audio[start_ms:end_ms]\n",
        "            clip = clip.normalize()\n",
        "            output_path = self.output_dir / output_filename\n",
        "            clip.export(output_path, format=\"wav\")\n",
        "            return str(output_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting clip: {e}\")\n",
        "            return None\n",
        "\n",
        "    def process_disfluencies(self, audio_path: str, disfluencies: List[Dict],\n",
        "                            recording_id: str) -> List[Dict]:\n",
        "        print(f\"\\nExtracting {len(disfluencies)} clips...\")\n",
        "        for idx, disf in enumerate(tqdm(disfluencies)):\n",
        "            disf_type = disf['type']\n",
        "            subtype = disf.get('subtype', 'unknown')\n",
        "            filename = f\"{recording_id}_disf_{idx:03d}_{disf_type}_{subtype}.wav\"\n",
        "            clip_path = self.extract_clip(\n",
        "                audio_path,\n",
        "                disf['start'],\n",
        "                disf['end'],\n",
        "                filename\n",
        "            )\n",
        "            disf['clip_filename'] = filename\n",
        "            disf['clip_path'] = clip_path\n",
        "            disf['duration_sec'] = disf['end'] - disf['start']\n",
        "        return disfluencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AudioPreprocessor:\n",
        "    @staticmethod\n",
        "    def preprocess_audio(input_path: str, output_path: str = None,\n",
        "                         target_sr: int = 16000, normalize: bool = True) -> str:\n",
        "        try:\n",
        "            audio = AudioSegment.from_file(input_path)\n",
        "\n",
        "            if audio.channels > 1:\n",
        "                audio = audio.set_channels(1)\n",
        "\n",
        "            if audio.frame_rate != target_sr:\n",
        "                audio = audio.set_frame_rate(target_sr)\n",
        "\n",
        "            if normalize:\n",
        "                audio = audio.normalize()\n",
        "\n",
        "            if output_path is None:\n",
        "                output_path = input_path.replace('.wav', '_preprocessed.wav')\n",
        "\n",
        "            audio.export(output_path, format=\"wav\")\n",
        "            return output_path\n",
        "        except Exception as e:\n",
        "            print(f\"Error preprocessing audio: {e}\")\n",
        "            return input_path\n",
        "\n",
        "    @staticmethod\n",
        "    def download_audio(url: str, output_path: str) -> bool:\n",
        "        url_patterns = [url]\n",
        "\n",
        "        if 'joshtalks-data-collection/hq_data' in url:\n",
        "            match = re.search(r'joshtalks-data-collection/hq_data/[a-z]{2}/(.*)', url)\n",
        "            if match:\n",
        "                remaining_path = match.group(1)\n",
        "                transformed_url = url.split('joshtalks-data-collection')[0] + f'upload_goai/{remaining_path}'\n",
        "                url_patterns.append(transformed_url)\n",
        "\n",
        "        for attempt_url in url_patterns:\n",
        "            try:\n",
        "                response = requests.get(attempt_url, stream=True, timeout=30)\n",
        "                response.raise_for_status()\n",
        "\n",
        "                with open(output_path, 'wb') as f:\n",
        "                    for chunk in response.iter_content(chunk_size=8192):\n",
        "                        f.write(chunk)\n",
        "\n",
        "                return True\n",
        "            except requests.exceptions.HTTPError as e:\n",
        "                if e.response.status_code == 404:\n",
        "                    continue\n",
        "                else:\n",
        "                    print(f\"Error downloading audio: {e}\")\n",
        "                    return False\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading audio: {e}\")\n",
        "                return False\n",
        "\n",
        "        print(f\"Error: Audio file not found at any URL pattern\")\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxOwVt4zA8un"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "\n",
        "    import shutil\n",
        "    if not shutil.which(\"ffmpeg\"):\n",
        "        print(\"=\"*60)\n",
        "        print(\"❌ ERROR: ffmpeg is not installed or not in PATH\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"\\nSee INSTALLATION_GUIDE.md for installation instructions.\")\n",
        "        return\n",
        "\n",
        "    pipeline = DisfluencyPipelineV2(\n",
        "        dataset_path=\"/content/FT_Data_-_data.csv\",\n",
        "        disfluency_list_path=\"/content/Speech Disfluencies List - Sheet1.csv\",\n",
        "        output_dir=\"output\"\n",
        "    )\n",
        "\n",
        "    results_df = pipeline.process_dataset(\n",
        "        max_recordings=5,\n",
        "        start_idx=0\n",
        "    )\n",
        "\n",
        "    print(\"\\n✓ Pipeline V2 completed successfully!\")\n",
        "    print(f\"✓ Check output/ directory for results\")\n",
        "\n",
        "    if results_df is None or len(results_df) == 0:\n",
        "        print(\"\\n⚠️  WARNING: No disfluencies detected or no audio files available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DisfluencyPipelineV2:\n",
        "    \"\"\"Complete pipeline for disfluency detection - Production Version.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset_path: str = \"/content/FT_Data_-_data.csv\",\n",
        "                 disfluency_list_path: str = \"/content/Speech Disfluencies List - Sheet1.csv\",\n",
        "                 output_dir: str = \"output\",\n",
        "                 local_audio_dir: str = None):\n",
        "        \"\"\"Initialize pipeline.\"\"\"\n",
        "        self.dataset_path = dataset_path\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.local_audio_dir = Path(local_audio_dir) if local_audio_dir else None\n",
        "\n",
        "        # Initialize components\n",
        "        self.detector = HindiDisfluencyDetectorV2(disfluency_list_path)\n",
        "        self.clipper = AudioClipper(output_dir=str(self.output_dir / \"disfluency_clips\"))\n",
        "        self.preprocessor = AudioPreprocessor()\n",
        "\n",
        "        # Audio cache\n",
        "        self.audio_cache = self.output_dir / \"audio_files\"\n",
        "        self.audio_cache.mkdir(exist_ok=True)\n",
        "\n",
        "    def process_recording(self, recording_id: str, audio_url: str,\n",
        "                         user_id: str = None) -> Tuple[List[Dict], str]:\n",
        "        \"\"\"Process a single recording.\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Processing Recording: {recording_id}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Check for local audio\n",
        "        audio_filename = f\"{recording_id}_audio.wav\"\n",
        "        audio_path = self.audio_cache / audio_filename\n",
        "\n",
        "        if self.local_audio_dir and not audio_path.exists():\n",
        "            local_path = self.local_audio_dir / audio_filename\n",
        "            if local_path.exists():\n",
        "                print(f\"Using local audio file: {local_path}\")\n",
        "                import shutil\n",
        "                shutil.copy(local_path, audio_path)\n",
        "\n",
        "        # Download if needed\n",
        "        if not audio_path.exists():\n",
        "            print(f\"Downloading audio from: {audio_url}\")\n",
        "            success = self.preprocessor.download_audio(audio_url, str(audio_path))\n",
        "            if not success:\n",
        "                print(f\"Failed to download audio for {recording_id}\")\n",
        "                return [], None\n",
        "        else:\n",
        "            print(f\"Using cached audio: {audio_path}\")\n",
        "\n",
        "        # Preprocess\n",
        "        print(\"Preprocessing audio...\")\n",
        "        preprocessed_path = self.preprocessor.preprocess_audio(str(audio_path))\n",
        "\n",
        "        # Detect disfluencies\n",
        "        disfluencies, transcription = self.detector.detect_all_disfluencies(preprocessed_path)\n",
        "\n",
        "        # Extract clips\n",
        "        disfluencies = self.clipper.process_disfluencies(\n",
        "            preprocessed_path,\n",
        "            disfluencies,\n",
        "            recording_id\n",
        "        )\n",
        "\n",
        "        # Add metadata\n",
        "        for disf in disfluencies:\n",
        "            disf['recording_id'] = recording_id\n",
        "            disf['user_id'] = user_id\n",
        "\n",
        "        return disfluencies, preprocessed_path\n",
        "\n",
        "    def process_dataset(self, max_recordings: int = None,\n",
        "                       start_idx: int = 0) -> pd.DataFrame:\n",
        "        \"\"\"Process entire dataset.\"\"\"\n",
        "        df = pd.read_csv(self.dataset_path)\n",
        "        print(f\"\\nLoaded dataset: {len(df)} recordings\")\n",
        "\n",
        "        if max_recordings:\n",
        "            df = df.iloc[start_idx:start_idx + max_recordings]\n",
        "            print(f\"Processing {len(df)} recordings (from index {start_idx})\")\n",
        "\n",
        "        # Load Whisper model once\n",
        "        self.detector.load_whisper_model(model_size=\"medium\")\n",
        "\n",
        "        # Process each recording\n",
        "        all_disfluencies = []\n",
        "\n",
        "        for idx, row in df.iterrows():\n",
        "            try:\n",
        "                disfluencies, _ = self.process_recording(\n",
        "                    recording_id=str(row['recording_id']),\n",
        "                    audio_url=row['rec_url_gcp'],\n",
        "                    user_id=str(row['user_id'])\n",
        "                )\n",
        "\n",
        "                all_disfluencies.extend(disfluencies)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing recording {row['recording_id']}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Create results DataFrame\n",
        "        results_df = pd.DataFrame(all_disfluencies)\n",
        "\n",
        "        if len(results_df) == 0:\n",
        "            print(\"\\n⚠️  No disfluencies detected!\")\n",
        "            return results_df\n",
        "\n",
        "        # Reorder columns\n",
        "        column_order = [\n",
        "            'recording_id', 'user_id', 'type', 'subtype',\n",
        "            'start', 'end', 'duration_sec',\n",
        "            'text', 'confidence',\n",
        "            'clip_filename', 'clip_path'\n",
        "        ]\n",
        "\n",
        "        for col in column_order:\n",
        "            if col not in results_df.columns:\n",
        "                results_df[col] = None\n",
        "\n",
        "        results_df = results_df[column_order]\n",
        "\n",
        "        # Save results\n",
        "        output_csv = self.output_dir / \"disfluency_results_v2.csv\"\n",
        "        results_df.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
        "        print(f\"\\n✓ Results saved to: {output_csv}\")\n",
        "        print(f\"✓ Total disfluencies detected: {len(results_df)}\")\n",
        "\n",
        "        # Print summary\n",
        "        self._print_summary(results_df)\n",
        "\n",
        "        return results_df\n",
        "\n",
        "    def _print_summary(self, df: pd.DataFrame):\n",
        "        \"\"\"Print summary statistics.\"\"\"\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"SUMMARY STATISTICS\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        print(f\"\\nTotal disfluencies: {len(df)}\")\n",
        "        print(f\"Unique recordings: {df['recording_id'].nunique()}\")\n",
        "\n",
        "        print(\"\\nDisfluency types:\")\n",
        "        type_counts = df['type'].value_counts()\n",
        "        for disf_type, count in type_counts.items():\n",
        "            percentage = (count / len(df)) * 100\n",
        "            print(f\"  {disf_type:15s}: {count:4d} ({percentage:5.1f}%)\")\n",
        "\n",
        "        print(f\"\\nDuration statistics:\")\n",
        "        print(f\"  Mean:   {df['duration_sec'].mean():.3f}s\")\n",
        "        print(f\"  Median: {df['duration_sec'].median():.3f}s\")\n",
        "        print(f\"  Min:    {df['duration_sec'].min():.3f}s\")\n",
        "        print(f\"  Max:    {df['duration_sec'].max():.3f}s\")\n",
        "\n",
        "        print(f\"\\nConfidence statistics:\")\n",
        "        print(f\"  Mean:   {df['confidence'].mean():.3f}\")\n",
        "        print(f\"  Median: {df['confidence'].median():.3f}\")\n",
        "        print(f\"  Min:    {df['confidence'].min():.3f}\")\n",
        "        print(f\"  Max:    {df['confidence'].max():.3f}\")\n",
        "\n",
        "        # Quality checks\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"QUALITY CHECKS\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        micro_segments = len(df[df['duration_sec'] < 0.05])\n",
        "        low_conf = len(df[df['confidence'] < 0.6])\n",
        "\n",
        "        print(f\"\\nMicro-segments (<0.05s): {micro_segments}\")\n",
        "        print(f\"Low confidence (<0.6): {low_conf}\")\n",
        "\n",
        "        if micro_segments == 0 and low_conf == 0:\n",
        "            print(\"\\n✅ All quality checks passed!\")\n",
        "        else:\n",
        "            print(\"\\n⚠️  Some quality issues detected\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3tNN1buBA9O",
        "outputId": "ca6a0d56-41b0-47c1-ec4d-8d7cb8b153d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "RUNNING PRODUCTION VERSION (V2) - STRICT VALIDATION\n",
            "======================================================================\n",
            "\n",
            "Running V2 Pipeline...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "    ╔══════════════════════════════════════════════════════════════╗\n",
            "    ║   Hindi Speech Disfluency Detection Pipeline V2             ║\n",
            "    ║   PRODUCTION VERSION - Strict Validation                    ║\n",
            "    ╚══════════════════════════════════════════════════════════════╝\n",
            "    \n",
            "✓ Loaded 33 filler patterns\n",
            "\n",
            "Loaded dataset: 104 recordings\n",
            "Processing 5 recordings (from index 0)\n",
            "Loading Whisper medium model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:17<00:00, 86.8MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Whisper model loaded\n",
            "\n",
            "============================================================\n",
            "Processing Recording: 825780\n",
            "============================================================\n",
            "Downloading audio from: https://storage.googleapis.com/joshtalks-data-collection/hq_data/hi/967179/825780_audio.wav\n",
            "Preprocessing audio...\n",
            "\n",
            "Processing: output/audio_files/825780_audio_preprocessed.wav\n",
            "  → Transcribing with Whisper...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 38896/38896 [21:37<00:00, 29.98frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  → Found 347 words\n",
            "  → Detecting fillers...\n",
            "     Found 0 fillers\n",
            "  → Detecting repetitions...\n",
            "     Found 0 repetitions\n",
            "  → Detecting prolongations...\n",
            "     Found 0 prolongations\n",
            "  → Detecting false starts...\n",
            "     Found 0 false starts\n",
            "  → Detecting hesitations...\n",
            "     Found 2 hesitations\n",
            "  → Removing overlaps...\n",
            "  ✓ Total unique disfluencies: 2\n",
            "\n",
            "Extracting 2 clips...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 89.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Processing Recording: 825727\n",
            "============================================================\n",
            "Downloading audio from: https://storage.googleapis.com/joshtalks-data-collection/hq_data/hi/967179/825727_audio.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing audio...\n",
            "\n",
            "Processing: output/audio_files/825727_audio_preprocessed.wav\n",
            "  → Transcribing with Whisper...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 39031/39031 [22:08<00:00, 29.37frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  → Found 751 words\n",
            "  → Detecting fillers...\n",
            "     Found 6 fillers\n",
            "  → Detecting repetitions...\n",
            "     Found 1 repetitions\n",
            "  → Detecting prolongations...\n",
            "     Found 0 prolongations\n",
            "  → Detecting false starts...\n",
            "     Found 5 false starts\n",
            "  → Detecting hesitations...\n",
            "     Found 5 hesitations\n",
            "  → Removing overlaps...\n",
            "  ✓ Total unique disfluencies: 16\n",
            "\n",
            "Extracting 16 clips...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:00<00:00, 130.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Processing Recording: 988596\n",
            "============================================================\n",
            "Downloading audio from: https://storage.googleapis.com/joshtalks-data-collection/hq_data/hi/1147542/988596_audio.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing audio...\n",
            "\n",
            "Processing: output/audio_files/988596_audio_preprocessed.wav\n",
            "  → Transcribing with Whisper...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 39298/39298 [22:40<00:00, 28.88frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  → Found 368 words\n",
            "  → Detecting fillers...\n",
            "     Found 0 fillers\n",
            "  → Detecting repetitions...\n",
            "     Found 0 repetitions\n",
            "  → Detecting prolongations...\n",
            "     Found 2 prolongations\n",
            "  → Detecting false starts...\n",
            "     Found 0 false starts\n",
            "  → Detecting hesitations...\n",
            "     Found 2 hesitations\n",
            "  → Removing overlaps...\n",
            "  ✓ Total unique disfluencies: 4\n",
            "\n",
            "Extracting 4 clips...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 113.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Processing Recording: 990175\n",
            "============================================================\n",
            "Downloading audio from: https://storage.googleapis.com/joshtalks-data-collection/hq_data/hi/1147542/990175_audio.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing audio...\n",
            "\n",
            "Processing: output/audio_files/990175_audio_preprocessed.wav\n",
            "  → Transcribing with Whisper...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 39120/40054 [17:53<00:15, 59.27frames/s]WARNING:whisper_timestamped:Got start time outside of audio boundary\n",
            "WARNING:whisper_timestamped:Got start time outside of audio boundary\n",
            "WARNING:whisper_timestamped:Got start time outside of audio boundary\n",
            "WARNING:whisper_timestamped:Got start time outside of audio boundary\n",
            "WARNING:whisper_timestamped:Got start time outside of audio boundary\n",
            "WARNING:whisper_timestamped:Got start time outside of audio boundary\n",
            "WARNING:whisper_timestamped:Got start time outside of audio boundary\n",
            "WARNING:whisper_timestamped:Got start time outside of audio boundary\n",
            "WARNING:whisper_timestamped:Got start time outside of audio boundary\n",
            "100%|██████████| 40054/40054 [18:25<00:00, 36.22frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  → Found 513 words\n",
            "  → Detecting fillers...\n",
            "     Found 6 fillers\n",
            "  → Detecting repetitions...\n",
            "     Found 7 repetitions\n",
            "  → Detecting prolongations...\n",
            "     Found 6 prolongations\n",
            "  → Detecting false starts...\n",
            "     Found 2 false starts\n",
            "  → Detecting hesitations...\n",
            "     Found 23 hesitations\n",
            "  → Removing overlaps...\n",
            "  ✓ Total unique disfluencies: 39\n",
            "\n",
            "Extracting 39 clips...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 39/39 [00:00<00:00, 130.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Processing Recording: 526266\n",
            "============================================================\n",
            "Downloading audio from: https://storage.googleapis.com/joshtalks-data-collection/hq_data/hi/639950/526266_audio.wav\n",
            "Preprocessing audio...\n",
            "\n",
            "Processing: output/audio_files/526266_audio_preprocessed.wav\n",
            "  → Transcribing with Whisper...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 47603/47603 [20:40<00:00, 38.37frames/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  → Found 395 words\n",
            "  → Detecting fillers...\n",
            "     Found 11 fillers\n",
            "  → Detecting repetitions...\n",
            "     Found 0 repetitions\n",
            "  → Detecting prolongations...\n",
            "     Found 0 prolongations\n",
            "  → Detecting false starts...\n",
            "     Found 15 false starts\n",
            "  → Detecting hesitations...\n",
            "     Found 50 hesitations\n",
            "  → Removing overlaps...\n",
            "  ✓ Total unique disfluencies: 76\n",
            "\n",
            "Extracting 76 clips...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 76/76 [00:00<00:00, 93.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Results saved to: output/disfluency_results_v2.csv\n",
            "✓ Total disfluencies detected: 137\n",
            "\n",
            "============================================================\n",
            "SUMMARY STATISTICS\n",
            "============================================================\n",
            "\n",
            "Total disfluencies: 137\n",
            "Unique recordings: 5\n",
            "\n",
            "Disfluency types:\n",
            "  hesitation     :   82 ( 59.9%)\n",
            "  filler         :   23 ( 16.8%)\n",
            "  false_start    :   21 ( 15.3%)\n",
            "  prolongation   :    8 (  5.8%)\n",
            "  repetition     :    3 (  2.2%)\n",
            "\n",
            "Duration statistics:\n",
            "  Mean:   4.299s\n",
            "  Median: 1.200s\n",
            "  Min:    0.160s\n",
            "  Max:    30.000s\n",
            "\n",
            "Confidence statistics:\n",
            "  Mean:   0.923\n",
            "  Median: 1.000\n",
            "  Min:    0.614\n",
            "  Max:    1.000\n",
            "\n",
            "============================================================\n",
            "QUALITY CHECKS\n",
            "============================================================\n",
            "\n",
            "Micro-segments (<0.05s): 0\n",
            "Low confidence (<0.6): 0\n",
            "\n",
            "✅ All quality checks passed!\n",
            "\n",
            "✓ Pipeline V2 completed successfully!\n",
            "✓ Check output/ directory for results\n",
            "\n",
            "======================================================================\n",
            "COMPARISON: V1 vs V2\n",
            "======================================================================\n",
            "\n",
            "V2 Results:\n",
            "  Total detections: 137\n",
            "  By type:\n",
            "    hesitation: 82\n",
            "    filler: 23\n",
            "    false_start: 21\n",
            "    prolongation: 8\n",
            "    repetition: 3\n",
            "\n",
            "======================================================================\n",
            "✓ V2 Pipeline Complete!\n",
            "✓ Results saved to: output/disfluency_results_v2.csv\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"RUNNING PRODUCTION VERSION (V2) - STRICT VALIDATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Backup old results if they exist\n",
        "if os.path.exists('disfluency_results.csv'):\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    backup_name = f'disfluency_results_v1_{timestamp}.csv'\n",
        "    import shutil\n",
        "    shutil.copy('disfluency_results.csv', backup_name)\n",
        "    print(f\"\\n✓ Backed up V1 results to: {backup_name}\")\n",
        "\n",
        "# Run V2 pipeline\n",
        "print(\"\\nRunning V2 Pipeline...\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "\n",
        "main()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPARISON: V1 vs V2\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load results\n",
        "v2_df = pd.read_csv('output/disfluency_results_v2.csv')\n",
        "\n",
        "# Find V1 backup\n",
        "v1_files = [f for f in os.listdir('.') if f.startswith('disfluency_results_v1_')]\n",
        "if v1_files:\n",
        "    v1_df = pd.read_csv(v1_files[-1])\n",
        "\n",
        "    print(f\"\\n{'Metric':<30} {'V1 (Old)':<15} {'V2 (New)':<15} {'Change':<15}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    # Total detections\n",
        "    v1_total = len(v1_df)\n",
        "    v2_total = len(v2_df)\n",
        "    change_pct = ((v2_total - v1_total) / v1_total * 100) if v1_total > 0 else 0\n",
        "    print(f\"{'Total Detections':<30} {v1_total:<15} {v2_total:<15} {change_pct:+.1f}%\")\n",
        "\n",
        "    # By type\n",
        "    print(f\"\\n{'By Type:':<30}\")\n",
        "    all_types = set(v1_df['type'].unique()) | set(v2_df['type'].unique())\n",
        "    for dtype in sorted(all_types):\n",
        "        v1_count = len(v1_df[v1_df['type'] == dtype])\n",
        "        v2_count = len(v2_df[v2_df['type'] == dtype])\n",
        "        change = ((v2_count - v1_count) / v1_count * 100) if v1_count > 0 else (100 if v2_count > 0 else 0)\n",
        "        print(f\"  {dtype:<28} {v1_count:<15} {v2_count:<15} {change:+.1f}%\")\n",
        "\n",
        "    # Quality metrics\n",
        "    print(f\"\\n{'Quality Metrics:':<30}\")\n",
        "\n",
        "    v1_micro = len(v1_df[v1_df['duration_sec'] < 0.05])\n",
        "    v2_micro = len(v2_df[v2_df['duration_sec'] < 0.05])\n",
        "    print(f\"  {'Micro-segments (<0.05s)':<28} {v1_micro:<15} {v2_micro:<15} {'-100%' if v2_micro == 0 else f'{((v2_micro - v1_micro) / v1_micro * 100):+.1f}%'}\")\n",
        "\n",
        "    v1_avg_dur = v1_df['duration_sec'].mean()\n",
        "    v2_avg_dur = v2_df['duration_sec'].mean()\n",
        "    print(f\"  {'Avg Duration (s)':<28} {v1_avg_dur:<15.3f} {v2_avg_dur:<15.3f} {((v2_avg_dur - v1_avg_dur) / v1_avg_dur * 100):+.1f}%\")\n",
        "\n",
        "    v1_avg_conf = v1_df['confidence'].mean()\n",
        "    v2_avg_conf = v2_df['confidence'].mean()\n",
        "    print(f\"  {'Avg Confidence':<28} {v1_avg_conf:<15.3f} {v2_avg_conf:<15.3f} {((v2_avg_conf - v1_avg_conf) / v1_avg_conf * 100):+.1f}%\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"IMPROVEMENTS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    improvements = []\n",
        "    if v2_total < v1_total * 0.5:\n",
        "        improvements.append(f\"✅ Reduced false positives by {100 - (v2_total/v1_total*100):.1f}%\")\n",
        "    if v2_micro == 0 and v1_micro > 0:\n",
        "        improvements.append(f\"✅ Eliminated all {v1_micro} micro-segments\")\n",
        "    if len(v2_df[v2_df['type'] == 'filler']) > 0 and len(v1_df[v1_df['type'] == 'filler']) == 0:\n",
        "        improvements.append(f\"✅ Now detecting fillers ({len(v2_df[v2_df['type'] == 'filler'])} found)\")\n",
        "    if v2_avg_conf > v1_avg_conf:\n",
        "        improvements.append(f\"✅ Improved average confidence by {((v2_avg_conf - v1_avg_conf) / v1_avg_conf * 100):.1f}%\")\n",
        "    if v2_avg_dur > v1_avg_dur:\n",
        "        improvements.append(f\"✅ Increased average duration (more meaningful segments)\")\n",
        "\n",
        "    if improvements:\n",
        "        for imp in improvements:\n",
        "            print(f\"\\n{imp}\")\n",
        "    else:\n",
        "        print(\"\\n⚠️  No significant improvements detected\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nV2 Results:\")\n",
        "    print(f\"  Total detections: {len(v2_df)}\")\n",
        "    print(f\"  By type:\")\n",
        "    for dtype, count in v2_df['type'].value_counts().items():\n",
        "        print(f\"    {dtype}: {count}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✓ V2 Pipeline Complete!\")\n",
        "print(f\"✓ Results saved to: output/disfluency_results_v2.csv\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHnnbOAOBiMK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
